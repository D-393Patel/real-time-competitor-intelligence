# ğŸ“Œ Milestone 2: Web Scraping & Data Aggregation

This module focuses on two core **data engineering and NLP tasks**:

- **Question Answering (QA)** using Transformer-based NLP models  
- **Web Scraping and Data Aggregation** from both dynamic and structured websites  

The goal is to analyze **QA model performance under varying questionâ€“context scenarios** and to implement **robust web scraping pipelines** using industry-standard tools.

---

## ğŸ¯ Objectives

- ğŸ” Evaluate transformer-based extractive Question Answering models  
- ğŸŒ Scrape dynamic JavaScript-rendered websites using Playwright  
- ğŸ•· Crawl structured paginated websites using Scrapy  
- ğŸ“ Store extracted data in CSV and JSON formats  
- âš™ Address real-world environment challenges in Google Colab  

---

## ğŸ›  Tools & Technologies Used

### ğŸ”  Programming & Environment

- Python 3.x  
- Google Colab (Linux)  

### ğŸ§  NLP & Machine Learning

- ğŸ¤— Hugging Face Transformers  
  - `deepset/roberta-base-squad2`  
  - `deepset/tinyroberta-squad2`  

### ğŸŒ Web Scraping

- ğŸ­ Playwright â€“ Dynamic & AJAX-rendered websites  
- ğŸ•· Scrapy â€“ Structured crawling and pagination  

### ğŸ“¦ Libraries & Dependencies

- asyncio, nest_asyncio  
- json, csv, pathlib  
- os, sys, subprocess, tempfile, site  
- Pandas â€“ Data handling & visualization  

---

## ğŸ§  NLP Question Answering Module

### ğŸ“Œ Description

- Uses pre-trained **RoBERTa models** fine-tuned on **SQuAD 2.0**
- Performs **extractive Question Answering** by identifying answer spans within a given context

### âš™ Implementation Highlights

- Uses `pipeline("question-answering")` from Hugging Face
- **Inputs:** Question + Context  
- **Outputs:** Predicted Answer + Confidence Score  

### ğŸ“ˆ Key Observations

- âœ… High confidence for direct, fact-based questions  
- âš  Lower confidence for indirect or inference-based questions  
- ğŸš« Correctly returns *no answer* for unrelated questions  
- âš¡ TinyRoBERTa performs efficiently for straightforward queries  

---

## ğŸŒ Web Scraping Module

### ğŸ­ Playwright (Dynamic Content)

**Target Website:**
- Laptops & Tablets â€“ `webscraper.io`

**Features:**
- Handles AJAX and JavaScript rendering
- Supports:
  - â€œLoad Moreâ€ buttons
  - Multi-page pagination

**Data Extracted:**
- Product title  
- Price  
- Rating  
- Product URL  
- Image URL  

**Output Formats:**
- CSV  
- JSON  

---

### ğŸ•· Scrapy (Structured Crawling)

**Target Website:**
- ğŸ“š `books.toscrape.com`

**Features:**
- Recursive pagination handling  
- CSS selector-based extraction  
- Textual â†’ numeric rating conversion  
- Absolute URL normalization  

**Google Colab Challenge Solved Using:**
- Temporary execution scripts  
- Manual `PYTHONPATH` configuration  
- `scrapy.cmdline.execute()` via subprocess  

---

## ğŸ“Š Data Preprocessing

- âœ‚ Whitespace trimming  
- ğŸ”¢ Rating standardization  
- ğŸ”— Relative â†’ absolute URL conversion  
- ğŸ“„ Direct serialization to CSV & JSON  

âš  No advanced normalization or currency conversion was applied to preserve raw extracted values.

---

## ğŸ“ˆ Model Evaluation

### ğŸ§  QA Model Evaluation

- Confidence score used as reliability indicator  
- Performs best when context relevance is high  
- Robust handling of unanswerable queries  

### ğŸŒ Web Scraping Validation

Validated through:
- Product count verification  
- Pandas DataFrame inspection  
- CSV & JSON output integrity checks  

---

## ğŸ Conclusion

This milestone successfully demonstrates:

- âœ… Practical application of Transformer-based QA models  
- âœ… Efficient scraping of both dynamic and static websites  
- âœ… Proper tool selection based on website architecture  
- âœ… Real-world debugging in cloud-based environments  

---

## ğŸš€ Future Enhancements

- ğŸ“Š Add Exact Match & F1-score evaluation for QA  
- ğŸ’± Normalize prices and textual attributes  
- ğŸ›¡ Handle CAPTCHAs and rate limiting  
- ğŸ”„ Integrate scraped data directly into QA pipelines  
